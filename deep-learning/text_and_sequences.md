# 深度学习之文本和序列

## 处理文本数据
文本向量化的几种思路
- 文本分割成单词，单词向量化
- 文本分割成字符，字符向量化
- 文本分割成单词或字符的n-gram，将每个n-gram向量化（n-gram是从句子中提取N个或更少的连续单词的集合，如对于句子a b c d， 2-gram提取的集合是{a, ab, b, bc, c, cd, d}，该集合叫二元语法袋）
### one-hot 编码
- one-hot
- 散列one-hot


### 词嵌入，也叫词向量
word embedding（或word vector），词嵌入是低维的浮点数向量，从数据中学习得到的，常见的维度256、512、1024
- 在完成主任务的时候同时学习词嵌入
先随机词向量，然后学习
- 预训练好词嵌入，直接用于模型


### 整合在一起：从原始文本到词嵌入


## 理解循环神经网络
循环神经网络（RNN、recurrent neural network）是具有内部环的神经网络，上一层的输出作为下一层的状态输入，状态输入+本层输入得到本层输出
### LSTM循环层
随着层数的增加容易出现梯度消失问题，随着层数的增加网络变得无法训练，继而就有了长短期记忆（LSTM，long short-term memory)。LSTM增加了一种携带信息跨越多个时间步的方法。

### GRU 层

## 循环神经网络的高级用法
### 使用循环dropout 来降低过拟合
### 循环层堆叠
### 使用双向RNN

## 用卷积神经网络处理序列
时间可以理解为一个空间维度
### 理解序列数据的一维卷积
### 序列数据的一维池化
### 实现一维卷积神经网络
### 结合CNN 和RNN 来处理长序列
